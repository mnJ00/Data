{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNSjbnmY45EmcgIPwop94B4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mnJ00/Data/blob/main/%EC%95%84%ED%8C%8C%ED%8A%B8_%EC%8B%A4%EA%B1%B0%EB%9E%98%EA%B0%80_%EC%98%88%EC%B8%A1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 아파트 실거래가 예측"
      ],
      "metadata": {
        "id": "I5Ay63ckXJ-m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDA"
      ],
      "metadata": {
        "id": "yFI632DvYGvd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CIukzjl4qfQz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "submission = pd.read_csv('sample_submission.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxWQbuk_xnlE",
        "outputId": "67bb42b6-50b1-4115-8648-d8df1d7b8654"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 15 columns):\n",
            " #   Column                             Non-Null Count  Dtype  \n",
            "---  ------                             --------------  -----  \n",
            " 0   user_id                            10000 non-null  object \n",
            " 1   subscription_duration              10000 non-null  int64  \n",
            " 2   recent_login_time                  10000 non-null  int64  \n",
            " 3   average_login_time                 10000 non-null  float64\n",
            " 4   average_time_per_learning_session  10000 non-null  float64\n",
            " 5   monthly_active_learning_days       10000 non-null  int64  \n",
            " 6   total_completed_courses            10000 non-null  int64  \n",
            " 7   recent_learning_achievement        10000 non-null  float64\n",
            " 8   abandoned_learning_sessions        10000 non-null  int64  \n",
            " 9   community_engagement_level         10000 non-null  int64  \n",
            " 10  preferred_difficulty_level         10000 non-null  object \n",
            " 11  subscription_type                  10000 non-null  object \n",
            " 12  customer_inquiry_history           10000 non-null  int64  \n",
            " 13  payment_pattern                    10000 non-null  int64  \n",
            " 14  target                             10000 non-null  int64  \n",
            "dtypes: float64(3), int64(9), object(3)\n",
            "memory usage: 1.1+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfaNhdtGPbyQ",
        "outputId": "0d781449-1c2a-4d87-9bc8-7db9c8a99ab4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 14 columns):\n",
            " #   Column                             Non-Null Count  Dtype  \n",
            "---  ------                             --------------  -----  \n",
            " 0   user_id                            10000 non-null  object \n",
            " 1   subscription_duration              10000 non-null  int64  \n",
            " 2   recent_login_time                  10000 non-null  int64  \n",
            " 3   average_login_time                 10000 non-null  float64\n",
            " 4   average_time_per_learning_session  10000 non-null  float64\n",
            " 5   monthly_active_learning_days       10000 non-null  int64  \n",
            " 6   total_completed_courses            10000 non-null  int64  \n",
            " 7   recent_learning_achievement        10000 non-null  float64\n",
            " 8   abandoned_learning_sessions        10000 non-null  int64  \n",
            " 9   community_engagement_level         10000 non-null  int64  \n",
            " 10  preferred_difficulty_level         10000 non-null  object \n",
            " 11  subscription_type                  10000 non-null  object \n",
            " 12  customer_inquiry_history           10000 non-null  int64  \n",
            " 13  payment_pattern                    10000 non-null  int64  \n",
            "dtypes: float64(3), int64(8), object(3)\n",
            "memory usage: 1.1+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "null_data = train[train['exclusive_use_area'].isnull()]\n",
        "null_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "9IPRNFPKYf8_",
        "outputId": "d4de643d-7a53-4ecc-b5e8-d43e836460a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'exclusive_use_area'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3802\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'exclusive_use_area'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-8aa620d4e148>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnull_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'exclusive_use_area'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnull_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3807\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3808\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3809\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3804\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3805\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'exclusive_use_area'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 컬럼간 관계 탐색: 도수분포(히스토그램)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize = (6,6))\n",
        "\n",
        "x = train[train['apartment_id'] == 2646]['exclusive_use_area']\n",
        "plt.hist(x, label='histogram')\n",
        "\n",
        "plt.xlabel('exclusive_use_area')\n",
        "plt.ylabel('number of apartment')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8R67iArsYf_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 결측값 대치 apartment_id의 median\n",
        "\n",
        "median_value = train.groupby('apartment_id')['exclusive_use_area'].median()\n",
        "median_value"
      ],
      "metadata": {
        "id": "-f4dmMpPYgJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 결측값(Null) 대치(2): merge()\n",
        "\n",
        "null_filled = pd.merge(median_value, null_data, on='apartment_id')\n",
        "null_filled"
      ],
      "metadata": {
        "id": "FvXmvYdtZHx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 결측값(Null) 대치(3): 형태 통일하기\n",
        "\n",
        "null_filled = null_filled.rename(columns={'exclusive_use_area_x':'exclusive_use_area'})\n",
        "null_filled = null_filled.drop(columns=['exclusive_use_area_y'])"
      ],
      "metadata": {
        "id": "vXE-x7P0ZICo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 결측값 대치 완료 데이터 만들기\n",
        "train_cleaned = train.dropna()\n",
        "train_filled = pd.concat([train_cleaned, null_filled])"
      ],
      "metadata": {
        "id": "6Bkt-34lZIKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 데이터 전처리: 칼럼 선정\n",
        "\n",
        "train_x = train_filled.drop(columns=['transaction_id', 'apartment_id', 'addr_kr', 'transaction_real_price'])\n",
        "train_y = train_filled['transaction_real_price']\n",
        "\n",
        "## 데이터 전처리: replace\n",
        "train_x = train_x.replace({'transaction_date': '1~10'} , 1)\n",
        "train_x = train_x.replace({'transaction_date': '11~20'} , 2)\n",
        "train_x = train_x.replace({'transaction_date': '21~31'} , 3)\n",
        "train_x = train_x.replace({'transaction_date': '21~29'} , 3)\n",
        "train_x = train_x.replace({'transaction_date': '21~30'} , 3)\n",
        "train_x = train_x.replace({'transaction_date': '21~28'} , 3)"
      ],
      "metadata": {
        "id": "hCcPp0zAZIRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 모델 학습 전 데이터 전처리(3): Label Encoding\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le_city = LabelEncoder()\n",
        "le_city = le_city.fit(train_x['city'])\n",
        "train_x['city'] = le_city.transform(train_x['city'])\n",
        "\n",
        "le_dong = LabelEncoder()\n",
        "le_dong = le_dong.fit(train_x['dong'])\n",
        "train_x['dong'] = le_dong.transform(train_x['dong'])\n",
        "\n",
        "le_jibun = LabelEncoder()\n",
        "le_jibun = le_jibun.fit(train_x['jibun'])\n",
        "train_x['jibun'] = le_jibun.transform(train_x['jibun'])\n",
        "\n",
        "le_apt = LabelEncoder()\n",
        "le_apt = le_apt.fit(train_x['apt'])\n",
        "train_x['apt'] = le_apt.transform(train_x['apt'])"
      ],
      "metadata": {
        "id": "7BNyNh7uZ23U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 선형회귀 모델 적용"
      ],
      "metadata": {
        "id": "eyU5HxG4azPv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 선형회귀 모델 훈련\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(train_x, train_y)"
      ],
      "metadata": {
        "id": "dCX7_-wcZ3AU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 예측 전 test 데이터 전처리\n",
        "test = pd.read_csv('test.csv')\n",
        "test.info()\n",
        "\n",
        "test_x = test.drop(columns=['transaction_id', 'addr_kr', 'apartment_id'])\n",
        "\n",
        "test_x = test_x.replace({'transaction_date': '1~10'} , 1)\n",
        "test_x = test_x.replace({'transaction_date': '11~20'} , 2)\n",
        "test_x = test_x.replace({'transaction_date': '21~31'} , 3)\n",
        "test_x = test_x.replace({'transaction_date': '21~29'} , 3)\n",
        "test_x = test_x.replace({'transaction_date': '21~30'} , 3)\n",
        "test_x = test_x.replace({'transaction_date': '21~28'} , 3)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "for city in np.unique(test_x['city']):\n",
        "    if city not in le_city.classes_:\n",
        "        le_city.classes_ = np.append(le_city.classes_, city)\n",
        "test_x['city'] = le_city.transform(test_x['city'])\n",
        "\n",
        "for dong in np.unique(test_x['dong']):\n",
        "    if dong not in le_dong.classes_:\n",
        "        le_dong.classes_ = np.append(le_dong.classes_, dong)\n",
        "test_x['dong'] = le_dong.transform(test_x['dong'])\n",
        "\n",
        "for jibun in np.unique(test_x['jibun']):\n",
        "    if jibun not in le_jibun.classes_:\n",
        "        le_jibun.classes_ = np.append(le_jibun.classes_, jibun)\n",
        "test_x['jibun'] = le_jibun.transform(test_x['jibun'])\n",
        "\n",
        "for apt in np.unique(test_x['apt']):\n",
        "    if apt not in le_apt.classes_:\n",
        "        le_apt.classes_ = np.append(le_apt.classes_, apt)\n",
        "test_x['apt'] = le_apt.transform(test_x['apt'])"
      ],
      "metadata": {
        "id": "jsZ4hw2VZ3Jj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 모델을 이용한 예측: test 데이터에 대해서 예측\n",
        "prediction = model.predict(test_x)\n",
        "\n",
        "submission = pd.read_csv('submission.csv')\n",
        "\n",
        "submission['transaction_real_price'] = prediction\n",
        "\n",
        "prediction"
      ],
      "metadata": {
        "id": "Og0ZLBYQaPZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "null_data = train[train['exclusive_use_area'].isnull()]\n",
        "null_data.count()"
      ],
      "metadata": {
        "id": "Hs6ePpEixqOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 검증데이터 만들기\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_split, validation = train_test_split(train, train_size=0.7)\n",
        "\n",
        "train_split = train_split.dropna()\n",
        "validation = validation.dropna()"
      ],
      "metadata": {
        "id": "I_IIOX22xr7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 데이터 전처리, 활용 컬럼 선정\n",
        "train_x = train_split[['exclusive_use_area', 'year_of_completion', 'transaction_year_month', 'floor', 'apartment_id']]\n",
        "train_y = train_split['transaction_real_price']\n",
        "\n",
        "valid_x = validation[['exclusive_use_area', 'year_of_completion', 'transaction_year_month', 'floor', 'apartment_id']]\n",
        "valid_y = validation['transaction_real_price']"
      ],
      "metadata": {
        "id": "oDMmUMx3HC-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##StandardScaler"
      ],
      "metadata": {
        "id": "4-r667HxD8Xc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 데이터 전처리(표준화)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "scaler.fit(train_x)\n",
        "train_x_scaled = scaler.transform(train_x)\n",
        "valid_x_scaled = scaler.transform(valid_x)"
      ],
      "metadata": {
        "id": "Ktb2w2s6HDF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 데이터 전처리 Principal Component Analysis, (1차원)\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=1)\n",
        "\n",
        "pca.fit(train_x_scaled)\n",
        "train_x_pca = pca.transform(train_x_scaled)\n",
        "valid_x_pca = pca.transform(valid_x_scaled)"
      ],
      "metadata": {
        "id": "vQo4R2PcHYbd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## LinearRegression 모델 평가\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "model_lr = LinearRegression()\n",
        "model_lr.fit(train_x_pca, train_y)"
      ],
      "metadata": {
        "id": "y40TZCcVHnkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize = (12,6))\n",
        "\n",
        "# 학습 데이터 시각화\n",
        "plt.scatter(train_x_pca, train_y, label='train data') #1\n",
        "plt.xlabel('train_x')\n",
        "plt.ylabel('train_y')\n",
        "\n",
        "# 모델의 학습 현황 시각화\n",
        "x_sorted = train_x_pca.tolist() #2\n",
        "x_sorted.sort() #3\n",
        "pred_lr = model_lr.predict(x_sorted) #4\n",
        "plt.plot(x_sorted, pred_lr, color='red', label='linear regression') #5\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OWlebuCCHnpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (12,6))\n",
        "\n",
        "plt.scatter(valid_x_pca, valid_y, label='validation data')\n",
        "plt.xlabel('valid_x')\n",
        "plt.ylabel('valid_y')\n",
        "\n",
        "x_sorted = valid_x_pca.tolist()\n",
        "x_sorted.sort()\n",
        "pred_lr = model_lr.predict(x_sorted)\n",
        "plt.plot(x_sorted, pred_lr, color='red', label='linear regression')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EPtjF1EZItpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## Decision Tree 모델 적용\n"
      ],
      "metadata": {
        "id": "zrvkMKPPa6L-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## . Decision Tree 모델 평가\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "model_dt = DecisionTreeRegressor()\n",
        "model_dt.fit(train_x_pca, train_y)"
      ],
      "metadata": {
        "id": "h2EOP-YvIxsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## train 데이터\n",
        "plt.figure(figsize = (12,6))\n",
        "\n",
        "plt.scatter(train_x_pca, train_y, label='train data')\n",
        "plt.xlabel('train_x')\n",
        "plt.ylabel('train_y')\n",
        "\n",
        "x_sorted = train_x_pca.tolist()\n",
        "x_sorted.sort()\n",
        "pred_dt = model_dt.predict(x_sorted)\n",
        "plt.plot(x_sorted, pred_dt, color='red', label='decision tree')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tGK4TxT7I2HE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 검증데이터\n",
        "plt.figure(figsize = (12,6))\n",
        "\n",
        "plt.scatter(valid_x_pca, valid_y, label='validation data')\n",
        "plt.xlabel('valid_x')\n",
        "plt.ylabel('valid_y')\n",
        "\n",
        "x_sorted = valid_x_pca.tolist()\n",
        "x_sorted.sort()\n",
        "pred_dt = model_dt.predict(x_sorted)\n",
        "plt.plot(x_sorted, pred_dt, color='red', label='decision tree')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vOJTkC6dI3YM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 랜덤포레스트 적용 전 데이터 전처리"
      ],
      "metadata": {
        "id": "D9HOqpHPbArI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train.isnull().sum()\n"
      ],
      "metadata": {
        "id": "AKVcWeUUvzXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.dropna(subset=['transaction_year_month'])\n",
        "train['transaction_year_month'].fillna('0', inplace=True)"
      ],
      "metadata": {
        "id": "JAoCNwkzvzfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 랜덤 포레스트 준비1, 데이터 전처리 -파생변수 생성\n",
        "import pandas as pd\n",
        "\n",
        "train['transaction_year'] = train['transaction_year_month'].astype(str).str[:4].astype(int)\n",
        "train['transaction_month'] = train['transaction_year_month'].astype(str).str[4:].astype(int)"
      ],
      "metadata": {
        "id": "35w9MnuCI56a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 데이터전처리-결측값 대치\n",
        "null_data = train[train['exclusive_use_area'].isnull()]\n",
        "median_value = train.groupby('apartment_id')['exclusive_use_area'].median()\n",
        "\n",
        "null_filled = pd.merge(median_value, null_data, on='apartment_id')\n",
        "null_filled = null_filled.rename(columns={'exclusive_use_area_x':'exclusive_use_area'})\n",
        "null_filled = null_filled.drop(columns=['exclusive_use_area_y'])\n",
        "\n",
        "train_cleaned = train.dropna()\n",
        "train_filled = pd.concat([train_cleaned, null_filled])"
      ],
      "metadata": {
        "id": "Ay3xZ7BWJnk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 모델 핛습 전 칼럼 선정\n",
        "train_x = train_filled.drop(columns=['transaction_id', 'apartment_id', 'addr_kr', 'transaction_year_month', 'transaction_real_price'])\n",
        "train_y = train_filled['transaction_real_price']"
      ],
      "metadata": {
        "id": "tLI9LpI4Lgs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 객체형 데이터 수치화\n",
        "train_x = train_x.replace({'transaction_date': '1~10'} , 1)\n",
        "train_x = train_x.replace({'transaction_date': '11~20'} , 2)\n",
        "train_x = train_x.replace({'transaction_date': '21~31'} , 3)\n",
        "train_x = train_x.replace({'transaction_date': '21~29'} , 3)\n",
        "train_x = train_x.replace({'transaction_date': '21~30'} , 3)\n",
        "train_x = train_x.replace({'transaction_date': '21~28'} , 3)"
      ],
      "metadata": {
        "id": "wro-OpNiLkWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le_city = LabelEncoder()\n",
        "le_city = le_city.fit(train_x['city'])\n",
        "train_x['city'] = le_city.transform(train_x['city'])\n",
        "\n",
        "le_dong = LabelEncoder()\n",
        "le_dong = le_dong.fit(train_x['dong'])\n",
        "train_x['dong'] = le_dong.transform(train_x['dong'])\n",
        "\n",
        "le_jibun = LabelEncoder()\n",
        "le_jibun = le_jibun.fit(train_x['jibun'])\n",
        "train_x['jibun'] = le_jibun.transform(train_x['jibun'])\n",
        "\n",
        "le_apt = LabelEncoder()\n",
        "le_apt = le_apt.fit(train_x['apt'])\n",
        "train_x['apt'] = le_apt.transform(train_x['apt'])"
      ],
      "metadata": {
        "id": "B46dmZyvLuB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 랜덤 포레스트 모델 검증"
      ],
      "metadata": {
        "id": "ZwNDi0YdbEx_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 랜덤포레스트 모델\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "model = RandomForestRegressor(random_state=777)"
      ],
      "metadata": {
        "id": "fUQan_qNLufa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 하이퍼 파라미터 튜닝: Gird Search Cross Validation\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = [{\n",
        "    'n_estimators': [9, 13],\n",
        "    'max_depth': [29, 33]\n",
        "    }\n",
        "]\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    model,\n",
        "    param_grid,\n",
        "    cv=2,\n",
        "    scoring='neg_root_mean_squared_error'\n",
        ")\n",
        "\n",
        "grid_search.fit(train_x, train_y)\n",
        "print('Done.')"
      ],
      "metadata": {
        "id": "r-JXe9UCLxGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 하이퍼 파라미터 튜닝 결과 확인\n",
        "result = pd.DataFrame(grid_search.cv_results_)\n",
        "result[['params', 'split0_test_score', 'split1_test_score', 'mean_test_score', 'rank_test_score']]"
      ],
      "metadata": {
        "id": "hzeLNmrnMEky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 최적 모델 학습\n",
        "\n",
        "best_model = RandomForestRegressor(n_estimators=9, max_depth=33, random_state=777)\n",
        "best_model.fit(train_x, train_y)\n"
      ],
      "metadata": {
        "id": "3hO3NEnOMLJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "n_iQUEJap6g_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 예측 전 test데이터 전처리\n",
        "\n",
        "test = pd.read_csv('test.csv')\n",
        "test['transaction_year'] = test['transaction_year_month'].astype(str).str[:4].astype(int)\n",
        "test['transaction_month'] = test['transaction_year_month'].astype(str).str[4:].astype(int)\n",
        "\n",
        "test_x = test.drop(columns=['transaction_id', 'addr_kr', 'apartment_id', 'transaction_year_month'])\n",
        "\n",
        "test_x = test_x.replace({'transaction_date': '1~10'} , 1)\n",
        "test_x = test_x.replace({'transaction_date': '11~20'} , 2)\n",
        "test_x = test_x.replace({'transaction_date': '21~31'} , 3)\n",
        "test_x = test_x.replace({'transaction_date': '21~29'} , 3)\n",
        "test_x = test_x.replace({'transaction_date': '21~30'} , 3)\n",
        "test_x = test_x.replace({'transaction_date': '21~28'} , 3)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "for city in np.unique(test_x['city']):\n",
        "    if city not in le_city.classes_:\n",
        "        le_city.classes_ = np.append(le_city.classes_, city)\n",
        "test_x['city'] = le_city.transform(test_x['city'])\n",
        "\n",
        "for dong in np.unique(test_x['dong']):\n",
        "    if dong not in le_dong.classes_:\n",
        "        le_dong.classes_ = np.append(le_dong.classes_, dong)\n",
        "test_x['dong'] = le_dong.transform(test_x['dong'])\n",
        "\n",
        "for jibun in np.unique(test_x['jibun']):\n",
        "    if jibun not in le_jibun.classes_:\n",
        "        le_jibun.classes_ = np.append(le_jibun.classes_, jibun)\n",
        "test_x['jibun'] = le_jibun.transform(test_x['jibun'])\n",
        "\n",
        "for apt in np.unique(test_x['apt']):\n",
        "    if apt not in le_apt.classes_:\n",
        "        le_apt.classes_ = np.append(le_apt.classes_, apt)\n",
        "test_x['apt'] = le_apt.transform(test_x['apt'])\n"
      ],
      "metadata": {
        "id": "Oc8C0YqXMd86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 랜덤포레스트 모델 이용 예측\n",
        "\n",
        "prediction = best_model.predict(test_x)\n",
        "\n",
        "submission = pd.read_csv('submission.csv')\n",
        "submission['transaction_real_price'] = prediction"
      ],
      "metadata": {
        "id": "60m1gpkQMeD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission"
      ],
      "metadata": {
        "id": "og1Fb35tNBGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LrCtOyPWQV1T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}